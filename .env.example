# LLM Configuration
# Set which LLM provider to use: 'openrouter' (default) or 'ollama'
LLM_PROVIDER=ollama

# Ollama settings (used when LLM_PROVIDER=ollama)
# If you're running Ollama locally use http://localhost:11434
# For Ollama Cloud gateway, set the appropriate host URL
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=gpt-oss:120b-cloud
# Optional: Ollama API key / token if required by your deployment
OLLAMA_API_KEY=

# OpenRouter / OpenAI fallback (leave blank if not using)
OPENROUTER_API_KEY=
OPENROUTER_MODEL=openai/gpt-oss-120b:free

# Data Source API Keys (optional)
OECD_API_KEY=
IMF_API_KEY=

# Project Configuration
PROJECT_NAME=Mises Data Curation
DATA_ROOT=.
