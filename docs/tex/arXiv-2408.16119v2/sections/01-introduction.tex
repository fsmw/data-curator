\section{Introduction}

In data exploration~\cite{rule2018exploration}, even when starting with an initial idea, analysts often need to go back and forth exploring a variety of charts before reaching their goals. Throughout this iterative process, analysts often discover insights that lead them into new directions. However, analysts need to tackle numerous execution challenges: in addition to varying chart specifications (as many current tools facilitate), they need to perform and manage different data transformations to support the desired visualization designs. 
For example, when exploring renewable energy trends, an analyst may find that similar trends across countries make a simple line chart (\autoref{fig:data-anvil-teaser}) too dense for detailed comparisons. This observation prompts the analyst to explore the renewable percentage trends of the top 5 CO$_2$ emitters and how the rankings of these countries have changed over time. To execute the plan, the analyst needs different data transformations: the first requires filtering the data based on each country's total CO$_2$ emissions, and the second requires partitioning the data by year to compute each country's ranking for that year.
%Similar chart authoring challenges are also relevant in the data-driven storytelling~\cite{ren2018reflecting,ren2019charticulator}, where authors needs to derive new data to refine chart designs (e.g., annotation). For example, to highlight which countries are leading in renewable energy adoption, the author might superimpose a trend line of global median adoption rates over the line chart; the author can later convert the chart into small multiples to tell a story about the most sustainable countries from each continent. Again, these new designs require data transformation from the current results.

%Managing different data and chart designs together in such iterative authoring processes can be challenging. As the analyst comes up with new chart designs, they need understand the data format expected by the chart and tool, and then transform data (e.g., reshaping, aggregation, window functions, string processing) using specific tools. 
Because data transformation can be difficult to learn and execute, many AI-powered tools have been developed~\cite{narechania2020nl4dv,wang2023data,wang2021falx,maddigan2023chat2vis,barke2023grounded,dibia2023lida}. These tools allow users to describe their goals using natural language and leverage AI models' code generation capabilities~\cite{chen2021evaluating,achiam2023gpt} to streamline data transformation and chart creation. Despite their success, current tools do not perform well in the \textit{iterative} visualization authoring context. Most of them require analysts to provide, in a single turn, a {text-only prompt} that {fully describes the complex visualization task to be performed}, which is usually unrealistic for both users and models.
\begin{itemize}[leftmargin=*]
\item First, even though free-form text prompts provide unbounded expressiveness for users to describe their goals, they miss UI interactions' precision and affordances, making it difficult for users to clearly describe complex chart designs.
%than graphical user interfaces (GUIs).
For example, to fully elaborate a faceted bar chart design, the user needs a verbose prompt to clearly specify visual encodings; without it, AI models often misinterpret the intent and create undesired charts, thus requiring further disambiguation efforts from the user. 
%On the other hand, with a shelf-configuration UI, users simply need to map data fields to their corresponding visual channels to specify the chart, and the system can provide immediate visual feedback to the user. 
In fact, writing high-quality prompts requires skill and effort. Even with clear goals,  inexperienced users sometimes find it difficult to clearly describe their intent in texts~\cite{zamfirescu2023johnny,DBLP:conf/chi/TankelevitchKSS24}.
\item Second, existing AI-powered tools do not accommodate branching or backtracking, behaviors that commonly occur in the iterative authoring process.
Using single-turn text-to-vis tools iteratively requires users to re-specify their intent from scratch for each new design, even for minor updates. This also increases the likelihood of the AI model failing, as it must solve a complex task in a single attempt. While chat-based tools~\cite{maddigan2023chat2vis,zheng2024opencodeinterpreter,openai2024gpt4technicalreport} support multi-turn interactions by reusing previous outputs, they struggle with branching contexts. Users often find it difficult to clearly specify which previous messages are relevant for the next iteration. With poorly specified contexts, models may struggle at retrieving important information from the lengthy conversation history to complete the task~\cite{liu2024lost,zhang2023tell,hsieh2024ruler}.
\end{itemize}

To address these iterative chart authoring challenges, our first key insight is to design a {\bf multi-modal chart builder} that blends the shelf-configuration UI~\cite{ren2019charticulator,wang2023data} with natural language (NL) input to enhance users' ability to structurally specify their chart designs. Resembling traditional shelf-configuration UIs, the chart builder lets user drag existing fields to corresponding visual channels to specify visual encodings. Additionally, users can type in field names that do not exist in the current data to express their intent for creating a visualization that requires data transformation. Coupled with a brief supplemental NL text that elaborates the design, the user can effectively communicate their goal to AI. 
Since the system can precisely extract chart configuration from the encoding shelf, the user doesn't need a verbose prompt to explicitly explain the design. The AI model then leverages the combined inputs to generate data transformation code to prepare the data required for the chart. 

Our second key insight is to introduce {\bf data threads}  for users to steer iteration directions. Data threads represent user's non-linear authoring history, allowing users to navigate to an earlier result, fork a new branch, and ask AI to create charts based on that context. This reduces users' input overhead by allowing them to specify incremental updates from a previous result (e.g., ``show only top 5 CO$_2$ emission countries' trends'', \autoref{fig:data-anvil-teaser}) rather than re-describing the full chart design from scratch. This design also benefits the AI models: the model can reuse previously generated code for new tasks to avoid repeating past mistakes, and it remains free from distractions caused by irrelevant messages from other threads. Data threads also provide a shortcut for users to backtrack and revise prompts to update recently created charts, allowing them to quickly clarify ambiguous inputs or fix errors made by AI.

%\bpstart{Blending UI and NL inputs for chart specification} The chart builder blends an shelf-configuration-like interface~\cite{ren2019charticulator,wang2023data} for users to specify visual encodings with a text box for them to provide supplemental NL instructions to elaborate the chart design. Resembling traditional shelf-configuration UIs, chart builder lets user drag existing fields to corresponding visual channels to specify the encodings; yet differently, it further allows users to type in field names that do not exist in the current data to express their intent for creating a visualization that requires data transformation. This blended input approach balances precision of UI inputs and flexibility of NL descriptions. Since system can precisely extract chart configuration from the encoding shelf, the user doesn't need a verbose prompt to explicitly explain the design; the system then sends the compiled inputs to the AI model to generate data transformation code and uses it to instantiate the chart.

%The structured inputs also benefits the AI model, as they guide the model to generate data transformation code that matches the chart design. With the chart design provided as contexts to the AI model, the model has more information to ground the user's instruction for better code generation.

%Resembling shelf-configuration UIs~\cite{ren2019charticulator,wang2023data}, users can drag existing data fields that they wish to visualize and drop them on visual channels in the chart builder to specify chart designs. \revised{Different from simple shelf designs, the chart builder allows users to input new data field names in the chart configuration, together with an (optional) supplemental NL instruction to explain the new fields, to express their intent for creating a visualization that require data transformation; the AI model can then take the compiled inputs from the shelf to transform the data and instantiate the chart accordingly. This blended input approach balances precision of UI inputs and flexibility of NL descriptions.} Since \tool can precisely extract chart specification from the encoding shelf, the user doesn't need a verbose prompt to explain the design. By conveying data semantics using NL inputs, the user delegates data transformation to AI. 

%\bpstart{Managing iteration directions} Data threads visualize users' interaction history with the AI and provide users the ability steer the iteration direction by providing different contexts to AI. For example, users can navigate to an earlier result, fork a new branch, and ask AI to create new charts following that contexts. This reduces users' input overhead, allowing them to specify incremental updates from a previous result (e.g., ``show only top 5 CO$_2$ emission countries' trends'', \autoref{fig:data-anvil-teaser}) as opposed to re-describing the full chart design from scratch. \revised{This design benefits the AI models: the model can reuse previously generated code towards new ones to avoid making mistakes encountered in the past, and it is free from distractions of (irrelevant) messages from other threads.}
%Behind the scene, the system tailors the conversation history to include only contexts relevant to that data to \revised{derive a new result so that the AI is free from distractions of (irrelevant) messages from other threads.} Data threads also provide a shortcut for users to quickly backtrack and revise prompts to update recently created charts, which can be useful for analysts to \revised{clarify ambiguous inputs or fix errors} made by AI.
%also accommodate users' disambiguation and clarification needs in their interaction with AI, where users can

\smallskip

Based on these designs, we developed \tool (\df for short), an AI-powered visualization tool for iterative visualization authoring.~\footnote{\tool is open sourced at \textcolor{urlcolor}{\url{https://github.com/microsoft/data-formulator}}}
\df supports diverse charts powered by the Vega-Lite grammar~\cite{satyanarayan2017vegalite}, and the AI model can flexibly transform data  for different designs, supporting operators like reshaping, filtering, aggregation, window functions, and column derivation. Like other AI tools~\cite{dibia2023lida,wang2023data}, \df provides users with panels to view generated data, transformation code and code explanations to inspect AI-generated contents. To understand how our new interaction designs benefit analysts in solving challenging data visualizations tasks, we conducted a user study consisting of eight participants with varying levels of data science expertise. They were asked to reproduce two professional data scientists' analysis sessions to create a total of 16 visualizations, 12 of which require non-trivial data transformations (e.g., rank categories by a criterion and combine low-ranked ones into one category with the label, ``Others''). The study shows that participants can quickly learn to use \df to solve these complex tasks, and the tool's flexibility and expressiveness allow participants to develop their own iteration, verification, and error correction styles to complete the tasks. Our inductive analysis of study sessions reveals interesting patterns of how users' experiences and expectations about the AI system affected their work styles. In summary, our main contributions are as follows:
\begin{itemize}[leftmargin=*]
    \item We designed new interaction approaches, specifically a multi-modal chart builder and a data threads view, to enhance users' ability to specify chart designs and control iteration directions.
    \item We implemented these designs in \df, an AI-powered interactive tool that supports the iterative creation of visualizations requiring data transformations.
    \item We conducted a user study that discovered data analysts' different iteration styles and rich experiences using our new interaction approaches to complete iterative chart authoring tasks. We observed that analysts  developed different styles iterating with the AI to perform data analysis, reflecting their personal experience and expectation with the AI model.
    %authoring, verification and iteration  to accommodate their experience and expectation with the AI model.
\end{itemize}

\begin{comment}

Ideally, the new interaction approach should provide an interface that are both expressive like chat-interface so that users can communicate complex data transformation needs concisely, but also supports precise specification and responsive feedback like graphical interfaces; it should also provide context-management supports to allow users easily navigate and reuse different versions of data iterated throughout the process. 

Based on these design reflections, we design a new interactive visualization tool, \tool, that provides a multi-modal interface that blends graphical and chat-based interface together, both reducing user efforts to more precisely specify their visualization intent and enhancing their control in the iterative process.



\chenglong{some thoughts: (1) prompting can be challenging, and it actually encourages users to create short and ambiguous prompts, which would increase further disambiguation and verification effort (2) the user could not expect what visualizations can or cannot be achieved, (3) the user can in fact easily specify their intent precisely from an UI but in chat they might omit it}



%\bpstart{Challenges} 
% To create rich visualizations, the author needs both conceptual knowledge about the diverse set of idioms from both chart authoring and data transformation (e.g., grammar of graphics~\cite{DBLP:books/daglib/0024564}, pivot tables, window functions~\cite{wickham2019tidyverse}) and execution skills (e.g., tool expertise or coding) to piece them together. 
% Recently, with the emergence of large language models (LLMs) that can automatically generate code from natural language (NL) (e.g., \cite{chen2021evaluating,achiam2023gpt}), AI-powered visualization tools (e.g., \cite{narechania2020nl4dv,wang2023data,wang2021falx,maddigan2023chat2vis,barke2023grounded,dibia2023lida}) have been developed to reduce skills and efforts required to achieve these tasks, allowing users to specify visualization with high-level descriptions or examples. 

However, despite their success, these tools do not fully address iterative visualization authoring challenges, because {they expect to complete the data transformation and visualization tasks in one attempt with one user input}. From the user's perspective, it can be challenging to convey their complete intent as one input to the system, as it is difficult to specify complex tasks both precisely and concisely. Furthermore, when the specification is unclear, the system is more prone to errors, and the user faces challenges to discover and fix AI's mistakes. Also, the requirement to solve the task in one attempt also puts burden on the AI system, as existing AI models cannot achieve perfect reliability and expressiveness at the same time~\cite{maddigan2023chat2vis,chen2021evaluating}. As a result, existing tools often have restricted expressiveness, especially for data transformation: Falx~\cite{wang2021falx} supports only data reshaping; Data Formulator's NL interface~\cite{wang2023data} is limited to column-wise computation; NL4DV~\cite{narechania2020nl4dv} and Graphy~\cite{chen2022type} require tidy input data. Although code assistants or chat-based interfaces provide great flexibility and expressiveness~\cite{achiam2023gpt}, allowing users to specify and refine their intents iteratively, they require users to be proficient in both prompting and programming, as the users needs to provide full context to clearly convey their intent~\cite{zamfirescu2023johnny} and understand the code produced by the AI to continue conversation~\cite{barke2023grounded} .
%(e.g., grammar of graphics for chart, relational algebras, pivot tables, and window aggregations for data) makes it difficult for non-experts to master all the tools necessary to achieve their visualizations To create rich visualizations, visualization authors face the skill challenge: they need knowledge to understand when and what data transformations they need to achieve their particular visualization goal; they then need to be adept at programming or with  specialized tools to implement the data transformations and create the chart. 

%Despite modern tools having greatly improved the user experience of transforming data and creating visualizations, situations where  authors need to iterate between these steps towards rich visualizations still face significant challenges. First, authors needs conceptual knowledge to understand when and what data transformations they need to achieve their particular visualization goal; they then need to be adept at programming or with  specialized tools to implement the data transformations and create the chart. The diverse set of idioms and user interfaces (UIs) (e.g., grammar of graphics for chart, relational algebras, pivot tables, and window aggregations for data) makes it difficult for non-experts to master all the tools necessary to achieve their visualizations. Even with proficient skills in individual tools, authors still face a significant overhead in switching their context between data transformation and visualization tools.  Moreover, the separation of such data and chart contexts makes version control difficult, especially when the author needs to backtrack, revise or explore alternative designs. While computational notebooks enable both data transformations and visualization creation inline, thus more naturally supporting an iterative editing process, they are, however, typically only accessible to programmers with deep familiarity with transformation and visualization libraries.

% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=\linewidth]{figures/global-energy-charts.png}
%     \caption{Visualizations created during the exploration of renewable energy trends based on \autoref{fig:global-energy-datatable}. Basic charts (1-3) show the distributions of CO$_2$ emission and Electricity from renewables and fossil fuels for each country over time. Charts 4-8 requires transforming the original dataset with pivoting, aggregation, calculation and merge: (4) a faceted chart that compares electricity from three sources for each country, (5) the trends of renewable energy percentage, and (6) renewable energy percentage trends for top-5 CO$_2$ emitting countries, (7) annotated line chart that includes global average with top CO$_2$ countries' trends, and (8) a bar chart that shows renewable differences for all countries between 2020 and 2000.}
%     \label{fig:global-energy-charts}
% \end{figure*}


% \begin{itemize}[leftmargin=12pt]\itemsep-1pt
% \item First, the author needs various skills to piece together their visualization goal. The author first needs conceptual knowledge to understand when they need to transform data, and what the desired data shape is for the given visualization goal. \todo{introduce pivot, filtering by top5 CO2 country} Then, the author needs to be adept at programming or with a specialized tool to transform the data appropriate for the particular chart. Because different tools follow very different idioms and user interfaces (UIs) (e.g., grammar of graphics and visual process computing for chart creation, relational algebra, pivot tables, and window aggregations in data transformation), mastering these tools can be daunting for non-experts.

% chart authoring experiences differs between  grammar-of-graphics based tools and visual process computation libraries; data transformation includes idioms like relational algebra, analytical function, reshaping, and measures, and they require different libraries or tools to achieve. 

% This knowledge is non-trivial, because seemingly semantically similar visualization goals may require very different data processing steps: e.g., “filtering the data to consider only year > 2000” is a simple filtering tasks that can be easily achieved within the visualization tool, but another task “filter to show trends of countries whose average CO2 emissions are among top 5” require aggregations, rankings and then filtering to produce the new data.


% Thus, in order to piece together a rich visualization, the author needs proficiency in multiple tools.

% \item Even when the author meets the skill requirements, they still need to take considerable efforts in order to achieve an iterative authoring process. In interactive tools, data transformation and chart creation are often separated into different contexts due to idiomatic difference, and this creates an overhead due to context-switching (authors often need to transform the data in one tool and import back to another tool for chart creation.)
% %For example, because many visualization tools expect tidy input data, the author needs to reshape the data in a tool they are familiar with (e.g., Excel) and import into Data Illustrator for chat creation; the author would go back to Excel if their new objective requires a different data shape. 
% Besides the cognitive overhead this entails, this separation also makes version control difficult, since each new input data creates a new visualization session separated from the previous efforts making it difficult for users to backtrack, revise or explore visualizations across multiple input data sources, and the user often needs to record and control their provenance using yet another tool.
% % \item Even just within the chart authoring, the process is linear: the authors are expected to have the final visualization in mind from the beginning, and newer edits are refinements of the previous ones that override the previous design. This impedes exploration tasks.
% Computational notebooks are often used to enable both data transformations and visualization creation, thus supporting an iterative editing process. Unfortunately, computational notebooks are typically only accessible to programmers.
% % Moreover, because first-class citizens in computation notebooks consists of lower-level operators (aggregation, table join, moving average), the high-level organization of the exploration process are often buried in detail, which requires the author needs additional efforts to annotate and organize the notebook.
%\end{itemize}

%Recently, with the emergence of large language models (LLMs) that can automatically generate code from natural language to solve programming tasks, AI-powered systems have been developed that significantly address the general lack of skills alluded to above (see Data Formulator, Copilots, NL2Vis, \todo{refer to existing AI-powered systems} for existing examples). Despite their successes, many of these tools have significant limitations for iterative authoring of rich visualizations. First, because AI-powered interactive tools aim to fully automate the data transformation and chart creation in one attempt from user inputs, they must compromise significantly with expressiveness for reliability, since existing AI models are not yet able to achieve perfect results for complex tasks. For example, Falx limits only to reshaping operators; Data Formulator requires users to choose different interfaces for reshaping vs computation to increase reliability at the cost of higher user mental load (programming by example approach); NL2Vis is limited to only visualizations from a fixed data shape. Second, because the user needs to pack their complete intent into one input to the system, complex tasks are difficult to specify precisely yet concisely. This also makes it difficult for authors to correct errors in AI outputs, since they need to restart fresh with a new input even when the result is close. Code assistants or chat-based interfaces with LLMs provides great flexibility and expressiveness, but they require the author to be proficient in prompting: the author needs to provide full context clearly to convey their intent. Then, because LLMs primarily respond with code, the author needs programming expertise to understand and verify the results.

% \begin{itemize}
% \item AI-powered interactive tools aim to fully automate the data transformation and chart creation in one attempt from user inputs. Thus, they must compromise significantly with expressiveness for reliability, because existing AI models are not yet able to achieve perfect results for complex tasks. For example, Falx limits only to reshaping operators; Data Formulator requires users to choose different interfaces for reshaping vs computation to increase reliability at the cost of higher user mental load (PBE); NL2Vis limits only to visualization from a fixed data shape. Furthermore, because the user needs to pack their intent as one input to the system, complex tasks are difficult to specify precisely yet concisely, which increase users’ specification effort.
% \item AI systems do not guarantee to always produce the correct results given the indeterministic nature of AI models and incompleteness of user specification. However, when results are incorrect, even when they are close, the user needs to restart fresh with a new input.
% \item Code assistants or the chat-based interface with LLMs provides great flexibility and expressiveness, but they require the author to be proficient in prompting: the author needs to provide full context clearly to convey their intent. Then, because LLMs primarily respond with code, the author needs programming expertise to understand and verify the results.
% \end{itemize}

%\bpstart{Our Solution} 
To address existing limitations, we designed an AI agent-based interactive visualization system, Data Anvil, with native iterative authoring support, letting users create and refine rich visualizations with high-level  {multi-modal} specifications.
\begin{itemize}[leftmargin=*]\itemsep-3pt
\item \bpstart{High-level specification powered by AI agents} Like existing AI systems, Data Anvil lets the user specify high-level intent and delegates the implementation task to AI agents. However, unlike existing chat-based tools where the user needs to specify everything via natural language (NL), Data Anvil combines graphical widgets and NL inputs to let them specify their intent more clearly with less overhead. Data Anvil provides the self-configuration user interface (UI)~\cite{grammel2013survey} for the user to specify visual encodings, and the user only needs to provide short descriptions to augment UI inputs to explain chart semantics. This design also benefits AI agents: the agents obtain rich information from UI interactions, NL inputs, and chat histories to better understand the user intent, which improves their reliability for complex tasks.
\item \bpstart{Native iteration support} Data Anvil supports iterative editing as a first-class interaction. From an existing visualization, the user can update NL and chart configuration (via UI) to describe how they want to modify an existing chart – whether the edit is a simple re-rendering of the charts with new encodings or a complex update requiring substantial data transformation. Based on these inputs, Data Anvil's agents reuse previously generated code and data to generate new results. The iteration support fundamentally expands the space of visualizations that can be achieved with Data Anvil while reducing user efforts. The user can solve complex tasks that are either difficult to specify in a single attempt by breaking them into smaller tasks, and each incremental specification is much easier to provide than starting from scratch. 
Data Anvil organizes the author’s interaction history as data threads to help the user manage analysis sessions. With data threads, the author can easily locate an existing plot to refine, fork a new branch from a previous step to explore alternatives, or backtrack to a previous state to correct mistakes.
\end{itemize}

With the benefit of multi-modal inputs and iteration capability, Data Anvil reliably supports expressive data transformation operators and chart specifications needed to author rich visualizations. It supports reshaping, filtering, aggregation, window functions, and column derivation, enabling users to compose diverse visualizations based on marks and encodings provided by Vega-Lite~\cite{satyanarayan2017vegalite}. To further improve system reliability, Data Anvil utilizes the self-repair technique~\cite{chen2023teaching} to self-debug errors in the generated code before returning to the user. Data Anvil also incorporates a chart assistant agent that helps inferring semantic types and natural orders of items in nominal fields (e.g., order of months written in English) to assist chart production. %Data Anvil's chart configuration component inherits a grammar of graphics-based design, which supports rich chart types and their compositions.
%Data Anvil further incorporates a semantic type inference agent which infers data types in encodings based on both the field name and values to bridge data and chart production.

Because AI models can make mistakes, Data Anvil provides information to assist users to inspect results. Like prior work~\cite{wang2023data}, Data Anvil tracks and presents generated visualizations, data tables, and the data transformation code from every iteration for user inspection. Data Anvil also translates the code into a step-by-step textual explanation to help non-coders understand the underlying data transformation process. When the author discovers undesired results, either caused by their unclear specification or AI model errors, they can easily backtrack and revise their prior inputs, or follow up with the AI agent with new instructions to correct the mistake, thanks to Data Anvil's iterative support.
%Data Anvil explain the transformation with a concise step-by-step textual summary automatically translated from the code.

To demonstrate \tool’s ability to assist in solving challenging data visualizations tasks, we conducted a user study with 8 participants with varying data science expertise, asking them to reproduce two professional data scientists' analysis sessions using Data Anvil; the two exploration sessions involved the reconstruction of 16 visualizations, 12 of which require non-trivial data transformations. Results show that participants quickly learned to use Data Anvil to solve these complex tasks within a two-hour session. Because of \tool’s flexibility and expressiveness in the authoring process,  participants employed multiple verification, error correction, and iteration strategies to complete the tasks. Through an inductive analysis of study sessions, we identified patterns of how users' expectations and trust with the AI system affected their styles of collaboration with the AI system. We conclude with a discussion on how the lessons learned from developing \tool can lead to future improvements in designing new AI system for data visualization. 
\end{comment}