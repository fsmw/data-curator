\section{Related Work}
\label{related-work}

Compared to its predecessor, Data Formulator~\cite{wang2023data}, \df has transitioned from a single-turn chart authoring tool into an iterative visualization tool designed for data exploration. Concretely, Data Formulator~\cite{wang2023data} is a single-turn authoring tool that leverages different authoring paradigms for various types of data transformations. It uses programming-by-example for table reshaping and employs LLMs to generate code for single column derivation. However, users may struggle with choosing the appropriate paradigm for the required transformations. \df unifies the interaction paradigms with a blended UI and natural language input design, supporting iterative authoring. This allows users to build new charts from previous ones with minimal additional specification. \df's new interaction approaches not only broaden the expressiveness of supported data transformations but also reduce the users' specification overhead. We next illustrate related work on  chart authoring, data transformation, and data exploration tools that inspired the design of \df.

\bpstart{LLM-powered visualization tools} Large language models' code generation ability~\cite{achiam2023gpt,chen2021evaluating,lozhkov2024starcoder,touvron2023llama} motivates the designs of new AI-powered visualizations tools~\cite{dibia2019data2vis,maddigan2023chat2vis,tian2024chartgpt,wang2023data} that allows users to create visualization using high-level natural language descriptions. For example,  LIDA~\cite{dibia2023lida} can summarize data and use LLM to generate python code to generate visualizations. Because LLMs can struggle in understanding complex chart logic,  ChartGPT~\cite{tian2024chartgpt} decomposes visualization tasks into fine-grained reasoning pipelines (e.g., column selection, filtering, chart type selection, visual encoding), using chain-of-thoughts prompting~\cite{wei2022chain}. As single-turn interactive tools, they are not suitable for iterative analysis. For multi-turn interactions, users can directly chat with LLMs in Code Interpreter~\cite{achiam2023gpt} or Chat2Vis~\cite{maddigan2023chat2vis}. Code Interpreter equips the LLM with a Python interpreter so that the model can generate and execute code to transform data and create charts; Chat2Vis includes visualization-specific prompts to help the model generate visualizations more reliably. Since these tools organize the dialog linearly, users need to put in extra effort to clarify the context when there are branches, to reduce the chances of models applying incorrect contexts and making mistakes in the new task~\cite{liu2024lost,zhang2023tell,hsieh2024ruler}. %Since these tools are based on NL inputs, users have to convert designs in their mind into potentially verbose texts to communicate their intent.

\df is also an LLM-powered tool that shares similar prompt designs to LIDA and Chat2Vis (e.g., the use of data summaries) and supports NL interaction. The key difference is that \df blends UI and natural language inputs for chart specification, balancing precision and flexibility, rather than requiring users to describe everything in text. 
\df's data threads generalize linear contexts used in existing dialog systems, allowing users to control the iteration direction by providing authoring contexts to the AI model.

\bpstart{Other AI and synthesis-powered tools} Besides LLM-powered tools above, neural semantic parsing~\cite{mitra2022facilitating,narechania2020nl4dv,chen2022type}, and program synthesis-based tools~\cite{wang2021falx} have also been developed to address the visualization challenge. For example, NL4DV~\cite{narechania2020nl4dv} and NcNet~\cite{luo2021natural} leverage recurrent neural networks trained to translate NL queries into charts. NL2Vis~\cite{wu2022nl2viz} and Graphy~\cite{chen2022type} use a semantic parser to extract entities from the user's NL query and apply program synthesis algorithms to compose charts. Unlike LLMs, these tools are more restrictive in the supported data transformations and chart types, requiring very specific chart descriptions from the user.  While programming-by-examples (PBE) techniques are developed to tackle data reshaping challenges in chart authoring (e.g., Falx~\cite{wang2021falx} and Data Formulator~\cite{wang2023data}'s reshaping module), users need to prepare low-level examples to demonstrate the transformation intent, which deviates users from the high-level visualization workflow. 
%Unlike LLM-based tools where the user can directly have conversation with the model to disambiguate inputs, semantic parsing and PBE-based tools develop special techniques for resolving ambiguous user intent. 
For disambiguation, DataTone~\cite{DBLP:conf/uist/GaoDALK15} introduces disambiguation widgets for users to experiment with different entity extraction outputs for the generated query, and users can inspect paraphrased queries (in NL) to resolve ambiguity; Falx~\cite{wang2021falx} previews charts from multiple versions of data consistent with user examples. Benefiting from the use of LLMs, \df is more expressive. Inspired by how prior work displays candidate results and explains code to help users understand system outputs~\cite{DBLP:conf/uist/GaoDALK15,gu2023analysts,wang2023data}, \df displays generated code, data, chart and code explanation to assist user inspection. %To resolve ambiguous outputs, the user can use data threads to follow up or backtrack and revise the their instructions.

%LIDA abstract: We present LIDA, a novel tool for generating grammar-agnostic visualizations and infographics. LIDA comprises of 4 modules - A SUMMARIZER that converts data into a rich but compact natural language summary, a GOAL EXPLORER that enumerates visualization goals given the data, a VISGENERATOR that generates, refines, executes and filters visualization code and an INFOGRAPHER module that yields data-faithful stylized graphics using IGMs.

% DATATONE abstract: In this work we propose a mixed-initiative approach to managing ambiguity in natural language interfaces for data visualization. We model ambiguity throughout the process of turning a natural language query into a visualization and use algorithmic disambiguation coupled with interactive ambiguity widgets.

%NL2Vis tools such as Lida~\cite{dibia2019data2vis} and NL4DV~\cite{narechania2020nl4dv} take a high-level description as input from the user and generate visualizations as output. Despite these tools excel at basic visualization tasks, they fail to produce high-quality results if the user description is insufficient -- especially when the task is too complex to be described in a short sentence. As the result, these tools are not suitable for iterative analysis, since the users need to describe their intent from scratch every iteration and the analysis goal can be difficult to describe in full in one sentence.

%Chat-based, or multi-turn NL, tools (...) are then developed to support the iterative visualization, where the user can provide follow-up instructions to ask the system to refine previous results so that the users don't need to start from scratch. Because these tools store the interaction history in a linear context, the user needs to put extra efforts in formulating a prompt to elaborate the contexts of the refinement instructions, otherwise the system could produce undesired results. Furthermore, because these systems expect only NL inputs, the user has to describe their chart configuration in NL, even though it can be more easily achieved using simple UI interactions as demonstrated in~\df. %, which adds additional specification efforts from the user.

%To remedy the specification challenge, tools like Data Formulator~\cite{wang2023data} provide multi-modal user interfaces that allows users to choose between UI and NL for different types tasks. However, it was shown

%Furthermore, DataTone~\cite{DBLP:conf/uist/GaoDALK15} like NL4DV~\cite{narechania2020nl4dv}, Lida~\cite{dibia2019data2vis}, DataTone~\cite{DBLP:conf/uist/GaoDALK15}, Data Formulator~\cite{wang2023data}, Data2Vis~\cite{dibia2019data2vis}, and Chat2Vis~\cite{maddigan2023chat2vis} are designed to let users create visualization from high-level inputs like natural languages, examples and demonstrations. 

%Data Anvil shares some similar designs with these tools. For example, Data Anvil leverages an NL interface to guide data derivation; Data Anvil's prompting strategy to interact with AI follows the similar designs in Lida and Data Formulator, using chain-of-thoughts prompting~\cite{wei2022chain} and data summary. There are several key differences. First, Data Anvil considers data transformation as part of the visualization authoring process~\cite{ren2018reflecting}, as opposed to focus only on chart generation from tidy inputs~\cite{narechania2020nl4dv}. Second, Data Anvil centers its designs around iteration, inspired by computation notebook~\cite{deline2021glinda,rule2018exploration}, dialog systems~\cite{gao2019neural,huang2020challenges} and exploratory search~\cite{gao2023neural}: comparing to tools that expect users to specify their intent all at once, Data Anvil let users break down complex tasks to solve them incrementally. Last, Data Anvil combines UI and NL for chart specification, inspired by multi-modal interfaces from other domains~\cite{DBLP:conf/uist/LiRJSMM19pumice}, so that user would not need verbose inputs for complex tasks needed in chat-based tools~\cite{maddigan2023chat2vis}. These designs better align Data Anvil for iterative visualization tasks.
%AI-assistants in computation notebooks~\cite{mcnutt2023design} and code editors~\cite{barke2023grounded,nguyen2022empirical} are also designed for data analysis. Despite their flexibility, they require users to be proficient at programming~\cite{barke2023grounded,gu2023analysts}.

%Since AI systems can generate incorrect results, verification techniques are developed to help user understand and correct errors. Data Anvil presents chart, data and code~\cite{wang2021falx,wang2023data} to  to assist users to examine both the computation and produced artifacts~\cite{gu2023analysts}. Data Anvil also incorporates AI-generated explanations to help non-coder understand the process~\cite{dibia2023lida}. Data Anvil then allows users to iterate with AI to correct errors. In future, Data Anvil can also benefit from explaining the computation process as diagrams~\cite{xiong2022visualizing,jiang2023log} or supporting interactive code or data editing~\cite{gordon2023co,drosos2023fxd} to improve users' trusts.


\bpstart{Visualization grammars and tools} The grammar of graphics~\cite{DBLP:books/daglib/0024564} inspired many modern visualization grammars (e.g., ggplot2~\cite{wickham2009ggplot2}, Vega-Lite~\cite{satyanarayan2017vegalite},
Altair~\cite{vanderplas2018altair}), where visualizations are mainly described by mappings from data columns to visual channels. Comparing to more expressive languages like D3~\cite{bostock2011d3} and Atlas~\cite{liu2021atlas}, high-level grammars hide the computation process of linking data items to visual objects to reduce visualization effort. Powered by these high-level grammars, interactive tools like Lyra~\cite{satyanarayan2014lyra}, Data Illustrator~\cite{liu2018data}, Charticulator~\cite{ren2019charticulator}, Tableau~\cite{stolte2002query}) have been introduced, where users leverage the shelf-configuration interface to specify visual encodings. To reduce authoring efforts, tools like Voyager~\cite{Wongsuphasawat2017voyager2}, Lux~\cite{lee2021lux}, and Draco~\cite{moritz2018formalizing} leverage rule and logic-based recommendation techniques to suggest visualizations from users' partial chart specifications. For example, Voyager lets users put a wildcard field into an encoding slot, and then automatically instantiates the wildcard field with different existing fields from the table, to produce interesting charts for users to explore. Note that these tools all require tidy input data~\cite{wickham2014tidy-data}, where all fields to be visualized should be data columns. Thus, users need to learn to use data transformation tools to prepare data~\cite{the_pandas_development_team_2023_7741580,wickham2019tidyverse,raman2001potter,kandel2011wrangler,polozov2015flashmeta,jin2017foofah,beth2020mage,huang2023interactive,chen2020multi}.

\df benefits from Vega-Lite's expressiveness to support rich visualization designs. \df inherits the shelf-configuration design from existing interactive tools and enhanced it with NL inputs for users to create charts that require data transformation.
While \df's custom fields resemble wildcard fields in Voyager~\cite{Wongsuphasawat2017voyager2}, they are semantically different: a custom field is for a field that users desire to visualize but not yet exist in the current table, requiring data transformation to surface, while a wildcard field refers to a field in the current table that the user does not specify explicitly. There is potential to unify these two as ``wildcard custom fields'' so that the system can recommend unspecified fields beyond the available fields in the current data (leveraging data transformation), which would broaden the exploration space.

%Programming libraries like pandas~\cite{the_pandas_development_team_2023_7741580}, R tidyverse~\cite{wickham2019tidyverse}, SQL~\cite{date1989guide}, and tools like Potter's Wheel~\cite{raman2001potter}, Wrangler~\cite{kandel2011wrangler}, Tableau Prep are developed to support data transformation. These tools support expressive data transformation idioms like relational algebra, reshaping, window function and string processing that are essential for data analysis. To lower the skill requirement of data transformation, automated data transformation tools are proposed, including programming-by-example tools  (e.g., FlashFill~\cite{polozov2015flashmeta,gulwani2017program}, Scythe~\cite{wang2017synthesizing}, Foofah~\cite{jin2017foofah}), mixed-initiative tools (e.g., Mage~\cite{beth2020mage}, Wrangler~\cite{kandel2011wrangler}), and natural language tools (e.g., NL2SQL~\cite{yu2018syntaxsqlnet,chen2020multi}, Rigel~\cite{huang2023interactive}). 
%Despite their convenience, visualization authors need conceptual knowledge to understand the desired data format. %Furthermore, many of existing tools restrict language expressiveness using domain specific  to improve system performance and reduce ambiguities from user specification, which limits their applicability to the authoring of rich visualizations.
%Data Anvil inherits the shelf-configuration design from existing interactive tools for chart specification. Data Anvil leverages LLMs~\cite{chen2021evaluating,achiam2023gpt} to generate expressive code to automate data transformation. In particular, Data Anvil unifies data and chart in the same contexts to reduce user efforts.

\bpstart{Exploration history} Graphical history~\cite{heer2008graphical} and data provenance~\cite{buneman2001and} are essential in visualization authoring, especially in exploration tasks where branching and iterations are common. In computation notebooks, the exploration history is organized based on code blocks~\cite{mcnutt2023design,observable}. Data transformation tools like somnus~\cite{xiong2022visualizing} and Tableau Prep visualize data provenance based on transformation operators. Directed-graph models~\cite{shi2019task,kim2017graphscape} based on visual similarity are also used for visualization organization. To assist data scientists manage (messy) programming histories in computation notebooks, Verdant~\cite{kery2017variolite} introduces a design that visualizes users' edit histories of notebook and artifacts, allowing them to revisit different versions of the notebook; code gathering tools~\cite{head2019managing} leverage data dependency to extract a clean and minimal code snippet from a notebook that can reproduce a variable of interest. To support the management of different versions of code snippets created during the ideation process, Variolite~\cite{kery2017variolite} allows users to explicitly create branches when experimenting different implementations of a function and to switch among them later on. 

\df's data threads draw inspiration from these systems. The key difference is that data threads are designed for users to steer iteration directions by providing authoring contexts with AI. This approach organizes history around high-level user interactions with AI and hides operator-level details. We characterized users' interaction strategies based on their exploration tree~\cite{white2007investigating}. Provenance management techniques for notebooks can be applied to manage long data threads users created across different sessions (e.g., compressing long data threads into shorter ones with summaries). In the future, \df could render data threads as hierarchical trees~\cite{kim2017graphscape} to support navigation of large data threads in multiple granularities. Additionally, it could incorporate version toggles, similar to Variolite, allowing users to explore different versions of generated code more compactly, rather than presenting all exploration branches as separate data threads.

%AI-assistants in computation notebooks~\cite{mcnutt2023design} and code editors~\cite{barke2023grounded,nguyen2022empirical} are also designed for data analysis. Despite their flexibility, they require users to be proficient at programming~\cite{barke2023grounded,gu2023analysts}.

\bpstart{Multi-modal interaction} Despite natural language providing flexible and expressive interactions between human and AI, NL-only interaction is not always optimal for the users to clearly convey their intent, especially for conveying designs  pictured only in the user's  mind. To address this limitation, multi-modal models like ChatGPT~\cite{achiam2023gpt} and Gemini~\cite{reid2024gemini} have been introduced, allowing users to provide audios and images in their conversation with AI. New interactive tools are also developed to support multi-modal interaction. For example, DirectGPT~\cite{masson2024directgpt} allows users to directly point and click on a canvas to specify contexts or objects that NL instruction is based on to reduce prompting effort, Mage~\cite{beth2020mage} provides interactive widgets for users to control content in notebook, and DynaVis~\cite{vaithilingam2024dynavis} generates UI widgets dynamically based on user's NL inputs for chart editing with LLMs so that users can explore and repeat edits and see instant visual feedback from edits. \df's chart builder bridges the precision and affordance of GUI interaction with flexibility of NL inputs and thus exploits a multi-modal UI design for visualization authoring.

