\section{Discussion and Future Work}

\bpstart{Supporting recommendations in exploratory analysis} 
\df focuses on visualization authoring, where an AI completes tasks needed to achieve a user's intended action. We envision that \df can be enhanced with recommendation capabilities like Voyager~\cite{Wongsuphasawat2017voyager2}, Draco~\cite{moritz2018formalizing}, and Lux~\cite{lee2021lux} for suggesting visualization goals to help users ``cold start'' their analysis. \df's designs can benefit user experiences with visualization recommendation tools in two ways. First, because \df supports visualization beyond initial data formats, it overcomes the limitation of most existing tools, which only consider fields in the input table for recommendation. Second, \df's data threads provide a natural way for users to follow up the system's initial recommendations, either to dive deeper into an exploration direction, revising suggested charts, or to ask for different recommendations. To achieve this, we can add a recommendation component that can suggest a list of fields to be explored and let \df prepare data to surface the fields and create visualizations. The initial recommendation of the fields of interests can be generated either automatically from the analysis of input data characteristics or in a mixed-initiative approach, i.e., leveraging AI to generate them using a high-level natural language instruction provided by the user --- these fields do not have to be fields in input data, as \df can transform the data to derive them from existing ones. While \df's data transformation ability can extend the visualization exploration space, thus bringing in more potential insights to be discovered, it also increases the chances of suggesting field combinations that are either trivial, distracting, or even biased. Therefore, as part of future work, it would be valuable to explore ways to support visual recommendation in a larger exploration space, especially managing and communicating exploration paths to the user to prevent unintentional bias towards an undesired direction.


\bpstart{Coordinating data transformation and chart editing} \df derives new data based on users' inputs to instantiate the chart design, but it does not modify the chart itself (represented as a Vega-Lite specification). When the user wants to refine the chart design (e.g., updating color scheme or $x$-axis ordering), they edit it through GUI widgets in the encoding panel after the chart is created. This design leverages the natural and precise nature of UI updates, providing immediate visual feedback~\cite{vaithilingam2024dynavis}. It also utilizes current models' strengths in data transformation for more reliable outputs~\cite{gao2023text,lai2023ds}. In contrast, current models perform less effectively in editing charts or generating charts from data based on NL instructions, even when the data is prepared~\cite{chen2024viseval}. Despite this, some participants in the user study showed interest in asking \df to perform chart edits within the chart builder alongside data transformation. A potential solution is an agent-based system~\cite{wu2023autogen,zhang2024training} that plans whether to transform data, edit the chart script, or both based on user inputs, and dispatches agents to handle these tasks. The key challenge is managing response time and maintaining reliability, as AI agents often require multiple interactions to reach consensus. %A potential direction is to experiment whether a multi-agent system composed of small language models~\cite{abdin2024phi} (for reduced model inference costs) can outperform a single LLM.  %It would be interesting future work to explore ways to integrate these approaches into interactive systems like \df to increase system expressiveness, while maintaining reliability and efficiency (e.g., minimizing chances for the planner to route user requests to wrong AI agent and reducing overall agent interaction rounds). 

%Furthermore, as \df currently focuses on grammar of graphics-based visualization supported in Vega-Lite, it provides limited supports of custom chart designs (e.g., new layouts, interaction, animation, or annotation) that require extensive editing after the chart is created. To support advanced editing, there are opportunities to incorporate direct manipulation interfaces in \df (e.g., canvas UI) so that users can directly manipulate marks~\cite{ren2019charticulator}, visual objects, and layouts~\cite{tsandilas2020structgraphics,saket2016visualization} to revise chart and improve its aesthetics. 

\bpstart{Asking users to clarify ambiguous inputs} \df adopts a generation verification approach: AI attempts to complete the user's request, and the user inspects the result to provide follow-up instructions. This interaction loop is enhanced by \df's local data thread design. There is an opportunity to make AI more proactive, such as actively seeking clarification from users when their inputs are ambiguous, before attempting to solve the task. This could reduce users' verification and revision efforts. For example, when the user issues an unclear request (e.g., \textit{``show top 5''}), the system can first analyze the goal, and then either present a refined goal for confirmation (e.g., \textit{``do you mean top 5 by renewable percentage?''}) or ask the users to clarify their intent (e.g., \textit{``what criteria should be used for ranking?''}). This proactive approach could also promote users' trust in the AI system. It is an interesting research direction to explore ways to prompt or train AI models to ask only necessary clarification questions, preventing users from being overwhelmed with low-level questions that might interrupt their workflow.

\bpstart{Study limitations} In our user study, we used the reproduction of professional data analysts' exploration sessions as the study tasks, rather than asking participants to perform free explorations. This choice was made to minimize the impact of participants' data analysis skills on their experience with \df, as our goal was not to assess their exploration skills. A follow-up study, where participants perform open exploration with their own data, can further investigate how \df can assist analysts with planning during exploration. In addition, as a limitation of our lab study, we could not capture users' longer-term learning effects. A future longitudinal study could further investigate how users' expectations with \df change over time and how this affects their specification styles and iteration strategies. %Therefore, it would be helpful to conduct a longitudinal study, asking participants to use \df in their workflow to explore data of their interests, characterizing their exploration processes and final conclusions using \df. 