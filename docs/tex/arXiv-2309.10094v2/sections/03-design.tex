\section{The Data Formulator Design}
\label{sec:design}

In this section, we describe our design principles, explain Data Formulator's interaction model, and how Data Formulator derives data concepts and formulates visualizations from the author's inputs.

\subsection{Design Principles}
Data Formulator introduces \emph{data concepts}, an abstraction of the columns needed for an author to specify their target visualization. To eliminate the author's burden to manually transform the data table before plotting, we designed Data Formulator based on the following guiding design principles.

\bpstart{Treat design concepts as first-class objects} The notion of data concepts is a generalization of table columns: it is a reference to columns both from a current table and from a future transformed table. They offer two benefits. First, concept-level transformations are easier to describe and understand than table-level operators. Table-level transformations require either advanced operators like \code{pivot} and \code{unpivot}, or high-order functions like {\sf\footnotesize map} and \code{window}, while concept-level operators are first-order functions over primitive elements (e.g., arithmetic) or lists (e.g., percentile). This makes it easier for the author to communicate with the AI agent and verify the results. Second, we can build the interaction experience on top of existing designs people are already familiar with: data concepts resemble data columns existing shelf-configuration tools commonly use.

\bpstart{Leverage benefits from multiple interaction approaches} Data Formulator employs both natural language interaction (for deriving concepts) and programming-by-example approach (for building custom concepts). Natural language descriptions have a superior ability to translate high-level intent into executable code and large language models (LLMs) can reason about natural concepts (e.g., academic grades are A, B, C, D, and F; months are from January to December). However, it can be difficult for the author to provide proper descriptions if they do not understand notions like pivoting, and natural language descriptions can be imprecise and ambiguous. In contrast, while program synthesizers cannot reason about natural concepts, they are less ambiguous, and it is easier for the author to convey reshaping operations by demonstrating the output relation. By incorporating multiple approaches and feedback for different transformation types (derivation vs. reshaping), Data Formulator takes advantage of both, reducing the specification barrier and improving the likelihood for the AI agent to generate correct and interpretable codes. 


\bpstart{Ensure correct data transformation and promote trust} While LLM and program synthesizers can automatically generate code to eliminate the author's manual data transformation burden, they can incorrectly generalize the author's specification. Therefore, it is crucial for the author to view and verify the results. Our design employs mechanisms to ensure such inspection by the author: (1) display multiple candidates for the author to review, if available, (2) display both the code (process) and the sample output values (results) to help the author understand the transformation, and (3) allow the author to edit the generated transformation code to correct or refine it.

\bpstart{Improve the system expressiveness} Data Formulator's expressiveness is defined by the combination of transformation function and visualization language. Data Formulator's visualization spec builds on top of Vega-Lite specifications. While Data Formulator's UI does not provide options to layer marks, the author can import their custom Vega-Lite specs of layered visualizations to achieve the same design. For data transformation, Data Formulator supports reshaping options from tidyverse as described in \cref{sec:user-experience}, and it supports both column-wise derivation and analytical computation that can be generated by the LLM. Note that while our transformation language does not include aggregation, the author can achieve the same visualization by setting aggregation options on the desired axes (e.g., map \code{Month} to $x$-axis and \code{avg(Seattle Temp)} to $y$-axis to create a bar chart with average temperature). However, with the current design, the author cannot derive or reshape data that first require aggregation without re-importing the aggregated data.

\subsection{Interaction Model}

\Cref{fig:design-program-overview} shows Data Formulator's high-level interaction model.
Data Formulator first loads data columns from the input table as original (and known) concepts (e.g., \code{Date}, \code{City}, and \code{Temperature} concepts in \cref{fig:data-formulate-ui}). 
The author uses the Concept Shelf to create new data concepts, if needed, in two ways (\cref{sec:create-concepts}): (1) derive a concept from existing ones by interacting with an AI agent using natural language or (2) build a custom concept by providing example values. If the new concept is derived from known concepts, Data Formulator immediately extends the current data table and registers it as a known concept.

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figures/design-data-formulator-architecture.png}
    \caption{Data Formulator's interaction model.}
    \label{fig:design-program-overview}
\end{figure}


With necessary data concepts known, the author uses the Chart Builder to map data concepts to visual channels of a chart. If unknown custom concepts are used to specify a visualization, Data Formulator asks the author to provide an example relation among the encoded concepts to transform the input table by using a programming-by-example approach.
With the necessary data formulations applied, Data Formulator generates a Vega-Lite spec and renders the visualization. 

\subsection{Creating New Data Concepts}
\label{sec:create-concepts}

The author can \textbf{derive} a concept from one or more data concepts by interacting with Data Formulator's AI agent (\cref{fig:design-program-overview}-\circled{1}).
%to translate high-level description into code. First, The author selects
In addition to a concept name, the author provides both a list of source concepts from which the new concept is derived and a natural language description of the transformation (\cref{fig:data-formulator-derive}-\circled{1}). Data Formulator then generates a contextualized prompt that grounds the description in the context of source concepts. %, and sends it to a large language model (LLM; we use Codex Davinci 2) to generate the transformation program (\cref{fig:design-derive-concept}-\circled{1}). 
This prompt combines the author's description and the descriptions of input parameters for all source concepts (with example values sampled from their domains) as comments, and joins it with the function prefix to instruct the AI agent to complete a Typescript function (as opposed to generate non-code text or uncontrolled code snippets). Data Formulator prepares two types of prompts for each query to cover simple derivation (Example 1) and analytical computation (Example 2) because it does not know if analytical computation is needed beforehand. 


\vspace{1mm}
\noindent \textbf{Example 1:} The prompt for ``Calculate seattle atlanta temp diff'' with source concepts \code{Seattle Temp} and \code{Atlanta Temp} (\cref{fig:data-formulator-derive}).
\begin{center}
\begin{smpage}{0.7\linewidth}
\begin{minted}[fontfamily=helvetica,fontsize=\small]{typescript}
// Calculate seattle atlanta temp diff
// @param seattleTemp examples: 51, 45, 48
// @param atlantaTemp examples: 45, 47, 56
(seattleTemp: number, atlantaTemp: number) => {
\end{minted}
\end{smpage}
\end{center}

\noindent \textbf{Example 2:} The prompt for ``calculate 7-day moving avg'' with source concept \code{Seattle Temp} (\cref{fig:data-formulator-derive-7-day-avg}). It provides \code{index} and \code{seattleTempList} so that the function can access to other values of the \code{seattleTemp} when analytical computation is needed (e.g., calculate the moving average for current index, derive percentile of the seatteTemp among all values).
\begin{center}
\begin{smpage}{0.95\linewidth}
\begin{minted}[fontfamily=helvetica,fontsize=\small]{typescript}
// calculate 7-day moving avg
// @param seattleTemp examples: 51, 45, 48
// @param seattleTempList: the list of all seattleTemp
(seattleTemp: number, index: number, seattleTempList: number[]) => { 
\end{minted}
\end{smpage}
\end{center}

%Data Formulator prepares both types of prompts because it does not know if analytical computation is needed beforehand. 
Data Formulator sends both prompts to LLM (we use Codex Davinci 2~\cite{chen2021evaluating}) to generate the transformation code (\cref{fig:design-program-overview}-\circled{2}), asking for five candidate completions. When candidate programs are returned from LLM, Data Formulator filters out programs that are not executable or contain error outputs by executing them on sample values from source domains. Data Formulator then presents the programs along with their example execution results for the author to inspect (\cref{fig:data-formulator-derive}). Once confirmed, a new derived concept is created and shown in the Concept Shelf. If all source fields are known concepts, Data Formulator derives a new column by applying the transformation function to every tuple from the source columns and appends the column in the current table for the author to review (e.g., \cref{fig:data-formulate-ui}).

%A derived concept is defined by a set of source concepts, a description of the transformation (provided by the author), and a Typescript function that implements the transformation (generated by Data Formulator and confirmed by the author). For example, the concept \code{Difference} in \cref{fig:data-formulator-derive} is a derived concept, represented as: \mintinline[fontfamily=helvetica,fontsize=\small]{json}{{"source": ["Seattle Temp", "Atlanta Temp"], "description": "Calculate seattle atlanta temp diff", "function": "(seattleTemp: number, atlantaTemp: number) => { return seattleTemp - atlantaTemp; };"}}. %When all source concepts are known, the derived concept is instantiated by applying the transformation function to every tuple from the source concepts. 

The author can also \textbf{build} a custom concept by providing its name and a set of example values that belong to its domain (\cref{fig:design-program-overview}-\circled{3}). Custom concepts are designed to support data reshaping: the author creates custom concepts when (1) the concept is spread across multiple columns; the author wants to combine multiple columns in a wide table to create one new concept in a long table, (2) multiple concepts are stored in one column; they want to surface fields from a long table, and (3) multiple values for a concept are collapsed in a column as a list (e.g., the value for an ``actors'' column is a list of actors for each movie); the author wants to split the list into multiple rows (i.e., one actor per row). 
These custom concepts are \textit{not} known yet upon creation because Data Formulator needs additional information from the author to resolve their relation with the input data. As we will describe in the next section, the resolution is achieved by inferring the reshaping program based on the  example relations provided by the user.
%Data Formulator uses the custom concepts later to infer the reshaping program.

With data concepts (including newly crated ones) ready, the author is ready to interact with the Chart Builder to create visualizations.

\subsection{Specifying and Formulating the Visualization} 

Chart Builder employs a shelf-configuration interface: authors drag-and-drop data concepts to visual channels of the selected visualization to specify visual encoding. Based on the encoding, Data Formulator generates a Vega-Lite specification (e.g., \cref{fig:design-vl-specs}) to render the visualization. Data Formulator adopts a chart-based specification: each chart type corresponds to a Vega-Lite template with placeholder encodings to be filled from the author specification. Data Formulator currently supports scatter plots (circle-based, bubble chart, ranged dot plots), bar charts (single-column, stacked, layered, grouped, histogram), line charts (with and without dots), heatmap, and custom charts (with all compatible visual channels). %\cref{fig:design-vl-specs} shows two examples of generated specs.

\begin{figure}[h]
\centering
\begin{smpage}{\linewidth}
\begin{minted}[fontfamily=helvetica,fontsize=\small]{json}
{ "mark": "circle", "encoding" : { "x": {"field": "Date", "type": "temporal"}, "y": {"field": "Temperature", "type": "quantitative"},  "color": {"field": "City"} } }

{ "mark": "circle",  "encoding" : { "x": {"field": "Seattle Temp", "type": "quantitative"}, "y": {"field": "Atlanta Temp", "type": "quantitative"} } }
\end{minted}
\end{smpage}
\caption{Vega-Lite specs for the scatter plots in \cref{fig:sea-atl-temp-pivot-derived}-1 and \cref{fig:data-formulator-pivot}.}
\label{fig:design-vl-specs}
\end{figure}

When all fields used in the visual encoding are available, Data Formulator combines the Vega-Lite spec with the input data to render the visualization (e.g., \cref{fig:sea-atl-temp-simple}). Otherwise, when some concepts are unknown (unresolved custom concepts or concepts derived from unknown ones), Data Formulator first interacts with the author and then calls the program synthesis engine to create the transformed table. 

Once the author specifies the visual encoding, Data Formulator first checks if any unknown concepts are used. If so, it asks the author to illustrate the relation of unknown concepts with other concepts used in the visual encoding by filling out an example relation in a sample table (e.g., \cref{fig:design-program-overview}-\circled{5}). Data Formulator needs such example relation to disambiguate the visualization intent because unknown concepts contain example values only from their own domains, missing information on how they will be related row-wise in the transformed table. For example, Data Formulator generates the example relation with \code{Seattle Temp} and \code{Atlanta Temp} fields as shown in \cref{fig:data-formulator-pivot}-\circled{3} for the author to complete. To reduce the author's efforts, Data Formulator pre-fills two example values of \code{Atlanta Temp} based on its sample domain and asks the author to complete their corresponding \code{Seattle Temp} values (e.g., what's \code{Seattle Temp} when \code{Atlanta Temp} is 45). Each row in the example relation will be a row in the transformed data, which will then be mapped to a point in the scatter plot.

Once the author submits the example relation, Data Formulator calls the program synthesizer to solve the data reshaping problem (\cref{fig:design-program-overview}-\circled{6}). Given an example relation $E$, with input data $T$, the program synthesizer solves the programming-by-example problem to find a reshaping program $p$ such that $E\subseteq p(T)$ (i.e., the transformed data should generalize the example $E$). The reshaping program $p$ is defined by the grammar in \autoref{fig:reshaping-operators}, where $p$ is recursively defined over four core reshaping operators from the R tidyverse library. We include only reshaping operators because other operators like \code{unite} and \code{summarise} are already supported by Data Formulator's ability to derive concepts from natural language. With this grammar, the program synthesizer performs an enumerative search in the program space for candidate programs. To speed up this combinatorial search process, we leverage abstract interpretation to prune the search space: the program synthesis engine returns candidate programs that satisfy the example relation to Chart Builder. Note that multiple candidates could be generated since the example relation is small and potentially ambiguous. In practice, unlike other programming-by-example tools, the small example relation is precise enough to constrain the program space that only the correct candidate is returned, because the program synthesizer only needs to solve the reshaping problem.

\begin{figure}
\[\arraycolsep=1.6pt
\begin{array}{rcll}
    p & \leftarrow &  T \\
      & | & \mathsf{pivot\_longer}(p, \bar{c}) & {\color{gray}\textit{(pivot from wide to long)}}\\
      & | & \mathsf{pivot\_wider}(p, c_{name}, c_{vals}) & {\color{gray}\textit{(pivot from long to wide)}}\\
      & | & \mathsf{separate}(p, c) &  {\color{gray}\textit{(split a column into two)}}\\
      & | & \mathsf{separate\_rows}(p, c) &  {\small\color{gray}\textit{(separate a collapsed column into rows)}}
\end{array}
\]
\vspace{-10pt}
\caption{Reshaping operators supported by Data Formulator. $T$ refers to input data, and $c$ refers to column names.}
\label{fig:reshaping-operators}
\end{figure}

With generated reshaping programs, Chart Builder prepares the input data: it first generates a reshaped table from each reshaping program and then for every derived concept used in the encoding, it extends the reshaped table with a new column by applying the transformation function on every tuple in the table. This way, Data Formulator generates a new table with all necessary fields to instantiate the visualization. 

Data Formulator presents the prepared table and candidate visualizations for the author to inspect (\cref{fig:data-formulate-ui}-\circled{3}\circled{4}). When the author confirms and saves a desired visualization, the transformed data is used to resolve unknown concepts: these concepts are now available as known concepts to be used to create visualizations. %, Data Formulator simply reuses saved transformed data to instantiate the visualization.

\new{
\subsection{Implementation} Data Formulator is built as a React web application in Typescript; its backend is a Python server that runs on a Dv2-series CPU with 3.5 GiB RAM on Azure. Data Formulator's backend queries the OpenAI Codex API for concept derivation and runs the synthesis algorithm locally. Data Formulator's scalability to larger data relates to (1) the frontend's visualization rendering capability and (2) the backend's efficiency to execute data transformation scripts. To scale up Data Formulator for large datasets, we envision a sampling-based approach~\cite{moritz2019falcon}, where Data Formulator presents results on a representative subset of data to enhance interactivity and returns full results asynchronously.
}
